{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import csv\n",
    "from random import seed\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML, display\n",
    "import gensim.downloader as api\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "from data_preprocessing import read_data,read_test, Tokenizer, TextDataset,\\\n",
    "    Vocab,train_test_split\n",
    "from utils import show_example\n",
    "from model import prepare_emb_matrix, RecurrentClassifier\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toxicity, such as insults, threats and hate speech, in online conversations is a real threat to productive sharing of opinons. To mitigate this problem automatic comment filtering system may be applied.\n",
    "In this assignment you are provided with data, collected by [Jigsaw](https://jigsaw.google.com/\n",
    ") company from Wikipediaâ€™s talk page edits. Each comment was labeled with toxicity rating from 0 to 5. Here are some examples of the least toxic comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = read_data()\n",
    "seed(4)\n",
    "\n",
    "# change this at your own risk \n",
    "ratings_to_show = (0, 1, 2)\n",
    "display(HTML(show_example(data, ratings=ratings_to_show)))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to build a classifier system. Let's create a baseline recurrent model. We'll start with building a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Press shift-tab to check docstrings\n",
    "tok = Tokenizer()\n",
    "tok_texts = [tok.tokenize(t) for t in chain(*data.values())]\n",
    "vocab = Vocab(tok_texts, max_vocab_size=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then data is splitted into train and validation parts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels, val_texts, val_labels = train_test_split(data)\n",
    "train_dataset = TextDataset([tok.tokenize(t) for t in train_texts], train_labels, vocab)\n",
    "val_dataset = TextDataset([tok.tokenize(t) for t in val_texts], val_labels, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pretrained embeddings are obtained with Gensim - it'll automatically download them for you. [Here](https://github.com/RaRe-Technologies/gensim-data#models\n",
    ") you can see other pretrained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# store embeddings in current directory\n",
    "os.environ[\"GENSIM_DATA_DIR\"] = str(Path.cwd())\n",
    "# will download embeddings or load them from disk\n",
    "gensim_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "emb_matrix = prepare_emb_matrix(gensim_model, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define hyperparameters for our baseline model. It'll be a 2-layered unidiractional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"freeze\": True,\n",
    "    \"cell_type\": \"LSTM\",\n",
    "    \"cell_dropout\": 0.3,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 128,\n",
    "    \"out_activation\": \"relu\",\n",
    "    \"bidirectional\": False,\n",
    "    \"out_dropout\": 0.2,\n",
    "    \"out_sizes\": [200],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 3e-4,\n",
    "    \"n_epochs\": 10,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "clf_model = RecurrentClassifier(config, vocab, emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=trainer_config[\"batch_size\"],\n",
    "                              shuffle=True,\n",
    "                              num_workers=8,\n",
    "                              collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=8,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "t = Trainer(trainer_config)\n",
    "t.fit(clf_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's save model, load it from checkpoint and check on some commments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t.save(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = Trainer.load(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_toxicity(model, comment):\n",
    "    tok_text = tok.tokenize(comment)\n",
    "    indexed_text = torch.tensor(vocab.vectorize(tok_text)).to(t.device)\n",
    "    rating = model(pack_sequence([indexed_text])).argmax().item()\n",
    "    print(f\"Toxicity rating for \\\"{comment}\\\" is: {rating}\") \n",
    "\n",
    "predict_toxicity(t.model, \"Please sir do not delete my edits\")\n",
    "predict_toxicity(t.model, \"They are nazi pal, forget it\")\n",
    "predict_toxicity(t.model, \"You suck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's prepare a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uuids, test_texts = read_test(\"data/test.csv\")\n",
    "test_dataloader = DataLoader( TextDataset([tok.tokenize(t) for t in test_texts], [-1] * len(test_texts), vocab), \n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=8,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "predictions = t.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_test_predictions(test_predictions, path):\n",
    "    assert len(test_predictions) == len(test_texts)\n",
    "    with open(path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow([\"uuid\",\"comment_text\",\"toxicity\"])\n",
    "        for uuid, text, pred in zip(test_uuids, test_texts, test_predictions):\n",
    "            writer.writerow([uuid, text, pred])\n",
    "        \n",
    "save_test_predictions(predictions, \"./best_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that generally not all errors are equal: for example, predicting score 0 while the target is 5 is seemingly worse than predicting 3 instead of 4. That's why your model will be evaluated by [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) loss used for regression tasks. Also note that your model is not required to predict integers, scores like 0.31, 2.718 etc. are fine too. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional part: automatic hyperparameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna is a framework which lets you easily tweak hypermarameters of your model. In this part we'll use it to improve quality on validation data - we'll select model with best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "BEST_ACC = 0.0\n",
    "\n",
    "def objective(trial):\n",
    "    global BEST_ACC\n",
    "    \n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 0, 3)\n",
    "    hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, 1000)\n",
    "    \n",
    "    config = {\n",
    "        \"freeze\": True,\n",
    "        \"cell_type\": trial.suggest_categorical(\"cell_type\", [\"RNN\", \"LSTM\", \"GRU\"]),\n",
    "        \"cell_dropout\": trial.suggest_loguniform(\"cell_dropout\", 1e-9, 0.9),\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 10, 1000),\n",
    "        \"out_activation\": trial.suggest_categorical(\"out_activation\", \n",
    "                                                    [\"sigmoid\", \"tanh\", \"relu\", \"elu\"]),\n",
    "        \"bidirectional\": trial.suggest_categorical(\"bidirectional\", [True, False]),\n",
    "        \"out_dropout\": trial.suggest_loguniform(\"out_dropout\", 1e-9, 0.9),\n",
    "        \"out_sizes\": [hidden_layer_size] * n_hidden_layers,\n",
    "    }\n",
    "\n",
    "    trainer_config = {\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-3),\n",
    "        \"n_epochs\": 10,\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-9, 1e-1),\n",
    "        \"batch_size\": 128,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    \n",
    "    pprint({**config, **trainer_config})\n",
    "        \n",
    "    clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "    t = Trainer(trainer_config)\n",
    "    t.fit(clf_model, train_dataloader, val_dataloader)\n",
    "    val_acc =  t.history[\"val_acc\"][-1]\n",
    "    if val_acc > BEST_ACC:\n",
    "        BEST_ACC = val_acc\n",
    "        t.save(\"optuna_model.ckpt\")\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "study = create_study(direction=\"maximize\")\n",
    "# you can set more trials\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = Trainer.load(\"optuna_model.ckpt\")\n",
    "save_test_predictions(t.predict(test_dataloader), \"./best_results_hparam_search.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainer.load(\"optuna_model.ckpt\")\n",
    "save_test_predictions(t.predict(test_dataloader), \"./best_results_hparam_search.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that generally not all errors are equal: for example, predicting score 0 while the target is 5 is seemingly worse than predicting 3 instead of 4. That's why your model will be evaluated by [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) loss used for regression tasks. Also note that your model is not required to predict integers, scores like 0.31, 2.718 etc. are fine too. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional part: automatic hyperparameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna is a framework which lets you easily tweak hypermarameters of your model. In this part we'll use it to improve quality on validation data - we'll select model with best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "BEST_ACC = 0.0\n",
    "\n",
    "def objective(trial):\n",
    "    global BEST_ACC\n",
    "    \n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 0, 3)\n",
    "    hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, 1000)\n",
    "    \n",
    "    config = {\n",
    "        \"freeze\": True,\n",
    "        \"cell_type\": trial.suggest_categorical(\"cell_type\", [\"RNN\", \"LSTM\", \"GRU\"]),\n",
    "        \"cell_dropout\": trial.suggest_loguniform(\"cell_dropout\", 1e-9, 0.9),\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 10, 1000),\n",
    "        \"out_activation\": trial.suggest_categorical(\"out_activation\", \n",
    "                                                    [\"sigmoid\", \"tanh\", \"relu\", \"elu\"]),\n",
    "        \"bidirectional\": trial.suggest_categorical(\"bidirectional\", [True, False]),\n",
    "        \"out_dropout\": trial.suggest_loguniform(\"out_dropout\", 1e-9, 0.9),\n",
    "        \"out_sizes\": [hidden_layer_size] * n_hidden_layers,\n",
    "    }\n",
    "\n",
    "    trainer_config = {\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-3),\n",
    "        \"n_epochs\": 10,\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-9, 1e-1),\n",
    "        \"batch_size\": 128,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    \n",
    "    pprint({**config, **trainer_config})\n",
    "        \n",
    "    clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "    t = Trainer(trainer_config)\n",
    "    t.fit(clf_model, train_dataloader, val_dataloader)\n",
    "    val_acc =  t.history[\"val_acc\"][-1]\n",
    "    if val_acc > BEST_ACC:\n",
    "        BEST_ACC = val_acc\n",
    "        t.save(\"optuna_model.ckpt\")\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "study = create_study(direction=\"maximize\")\n",
    "# you can set more trials\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = Trainer.load(\"optuna_model.ckpt\")\n",
    "save_test_predictions(t.predict(test_dataloader), \"./best_results_hparam_search.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
